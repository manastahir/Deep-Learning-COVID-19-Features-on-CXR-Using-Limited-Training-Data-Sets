[BASE]
;base folder containing the image folders
base_dir=../data/Images


[SEG]
; model_data directory to store and load data for the current experiment
output_dir=../experiments/experiment_3/Segmentation

; base model name
; one of: DenseNet103, UNET
model_name=DenseNet103


;Number of classes
num_classes=2

; use base model weights or not. If true, imagenet pretrained weights will be used for classification model
use_base_model_weights=false

; if true, load trained model weights saved in output_dir
; this is typically used for resuming your previous training tasks
; so the use_split_dataset will be automatically set to false
; also, make sure you use the reasonable initial_learning_rate
use_trained_model_weights=false

; if true, use best weights, else use last weights
use_best_weights=false

; note that the best weighting will be saved as best_weights.h5
output_weights_name=DenseNet103_weights.h5

; output json model file
output_json_name=DenseNet103.json

; basic training parameters
epochs=100
batch_size=2

; learning rate options
initial_learning_rate=1e-4

; worker number of the image generators
generator_workers=8

; target width/height of the input image (resized)
image_dimension=256

; steps per epoch for training
; auto or int
; if auto is set, (total samples / batch_size / 10) is used by default.
train_steps=auto

; steps per epoch for validation
; auto or int
; if auto is set, (total samples / batch_size / 5) is used by default.
validation_steps=auto

; patience parameter used for ReduceLROnPlateau callback
; If val_loss doesn't decrease for x epochs, learning rate will be reduced by factor of 10.
patience_reduce_lr=5

; patience parameter used for EarlyStopping callback
; If loss doesn't decrease for x epochs, Trainig will stop
patience_early_stop=7

; minimun learning rate
min_lr=1e-8

; path of the folder that contains train.csv|dev.csv|test.csv
dataset_csv_dir=../splits/Segmentation

; print model summary
show_model_summary=false



[CLASS]
; model_data directory to store and load data for the current experiment
output_dir=../experiments/experiment_3/Classification

; base model name
; one of: DenseNet103, UNET
model_name=Resnet18

; class names, you should not modify this
class_names=Normal,Tb,Bacterial Pneumonia,Viral Pneumonia

;folder containing segmentation masks
mask_folder=classification masks

; use base model weights or not. If true, imagenet pretrained weights will be used for classification model
use_base_model_weights=true

; if true, load trained model weights saved in output_dir
; this is typically used for resuming your previous training tasks
; so the use_split_dataset will be automatically set to false
; also, make sure you use the reasonable initial_learning_rate
use_trained_model_weights=false

; if true, use best weights, else use last weights
use_best_weights=false

; note that the best weighting will be saved as best_weights.h5
output_weights_name=Resnet18_weights.h5


; basic training parameters
epochs=100
batch_size=4

; learning rate options
initial_learning_rate=1e-4

; worker number of the image generators
generator_workers=1

; target width/height of the input image (resized)
image_dimension=1024

;target patch size generated
patch_size=256

; steps per epoch for training
; auto or int
; if auto is set, (total samples / batch_size / 10) is used by default.
train_steps=auto

; steps per epoch for validation
; auto or int
; if auto is set, (total samples / batch_size / 5) is used by default.
validation_steps=auto

; patience parameter used for ReduceLROnPlateau callback
; If val_loss doesn't decrease for x epochs, learning rate will be reduced by factor of 10.
patience_reduce_lr=3

; patience parameter used for EarlyStopping callback
; If loss doesn't decrease for x epochs, Trainig will stop
patience_early_stop=7

; minimun learning rate
min_lr=1e-8

; this variable controlls the class_weight ratio between 0 and 1
; higher value means higher weighting of positive samples
positive_weights_multiply=1


; path of the folder that contains train.csv|dev.csv|test.csv
dataset_csv_dir=../splits/Classification

; print model summary
show_model_summary=true


[TEST]
; model_data directory to store and load data for the current experiment
output_dir=../experiments/experiment_3/Classification

batch_size=16


N = 20

; if true, use best_weights.h5, else use weights.h5
use_best_weights=true
